{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7b0d7a0-006f-4d9f-a8c9-04d3d2a0e5b7",
   "metadata": {},
   "source": [
    "# Stock Price Prediction with Random Forest and Technical Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d6f51c-43a9-4b68-b7c1-0c5a2c20689b",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b29d91f-0e10-4f51-b924-a7e2b85e09f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (from scikit-learn) (1.15.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\documents\\gisma\\data mining\\stock-predictions\\data_mining_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages (uncomment if not already installed)\n",
    "%pip install pandas scikit-learn matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3c0e1e-f3b1-4f10-9b34-d0e1c3e3a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import sys\n",
    "import pathlib\n",
    "\n",
    "# Add the 'Main' directory to the system path to import custom modules\n",
    "main_path = pathlib.Path(\"..\", \"Main\").resolve()\n",
    "sys.path.append(str(main_path))\n",
    "\n",
    "from data_collection import StockDataCollector\n",
    "from data_cleaning import StockDataCleaner\n",
    "from technical_indicators import TechnicalIndicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a6d91f-0e10-4f51-b924-a7e2b85e09f5",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e2b85e-09f5-4f51-b924-a7e2b85e09f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for data in: c:\\Users\\LENOVO\\Documents\\GISMA\\Data Mining\\Stock-Predictions\\Datasets\\Historical Data\n",
      "Successfully loaded 5 tickers\n",
      "Apple Stock (first 5 rows):\n",
      "        Date   Close    Volume    Open    High       Low\n",
      "0 2025-06-13  196.45  51447350  199.73  200.37  195.7000\n",
      "1 2025-06-12  199.20  43904640  199.08  199.68  197.3601\n",
      "2 2025-06-11  198.78  60989860  203.50  204.50  198.4100\n",
      "3 2025-06-10  202.67  54672610  200.60  204.35  200.5700\n",
      "4 2025-06-09  201.45  72862560  204.39  206.00  200.0200\n",
      "\n",
      "Apple Stock (last 5 rows):\n",
      "           Date   Close     Volume     Open     High      Low\n",
      "2511 2015-06-19  31.650  217446120  31.9275  31.9550  31.6000\n",
      "2512 2015-06-18  31.970  141455960  31.8075  32.0775  31.8050\n",
      "2513 2015-06-17  31.825  131435600  31.9300  31.9700  31.6850\n",
      "2514 2015-06-16  31.900  125774600  31.7575  31.9625  31.5925\n",
      "2515 2015-06-15  31.730  175587840  31.5250  31.8100  31.4275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Collect data\n",
    "collector = StockDataCollector(historical_data_path='../Datasets/Historical Data') # specify the path of dataset dir\n",
    "collector.collect_data()\n",
    "\n",
    "# 2. Clean data\n",
    "cleaner = StockDataCleaner()\n",
    "cleaned_data = cleaner.clean_all(collector)\n",
    "\n",
    "# Using Apple data (or any other ticker available)\n",
    "AAPL = cleaned_data[\"AAPL\"].copy() # .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "print(f\"Apple Stock (first 5 rows):\\n{AAPL.head()}\\n\")\n",
    "print(f\"Apple Stock (last 5 rows):\\n{AAPL.tail()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a6d91f-0e10-4f51-b924-a7e2b85e09f5",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering (Lagged Prices & Technical Indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7a2b85e-09f5-4f51-b924-a7e2b85e09f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL data with indicators (first 5 rows after dropping NaNs):\n",
      "           Date    Close    Volume     Open     High      Low  Previous_Close  \\\n",
      "2024 2017-05-25  38.4675  76871240  38.4325  38.5875  38.2575         38.4025   \n",
      "2025 2017-05-24  38.3350  76807280  38.4600  38.5425  38.1675         38.4675   \n",
      "\n",
      "        SMA_50    SMA_200    EMA_12     EMA_26      MACD  MACD_Signal  \\\n",
      "2024  37.25670  40.537262  38.09554  37.653040  0.442499     0.312869   \n",
      "2025  37.24145  40.501787  38.13238  37.703556  0.428824     0.336060   \n",
      "\n",
      "      MACD_Hist        RSI   Stoch_%K   Stoch_%D   BB_Upper   BB_Lower  \\\n",
      "2024   0.129631  59.693137  84.335561  83.453602  39.700122  35.220878   \n",
      "2025   0.092764  57.893092  80.400891  82.508374  39.772714  35.341036   \n",
      "\n",
      "           ATR  \n",
      "2024  0.663188  \n",
      "2025  0.642603  \n",
      "\n",
      "Columns available for features: ['Date', 'Close', 'Volume', 'Open', 'High', 'Low', 'Previous_Close', 'SMA_50', 'SMA_200', 'EMA_12', 'EMA_26', 'MACD', 'MACD_Signal', 'MACD_Hist', 'RSI', 'Stoch_%K', 'Stoch_%D', 'BB_Upper', 'BB_Lower', 'ATR']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create lagged closing price as a baseline and feature (avoiding data leakage)\n",
    "AAPL['Previous_Close'] = AAPL['Close'].shift(1)\n",
    "\n",
    "# Calculate all technical indicators\n",
    "aapl_with_indicators = TechnicalIndicators.calculate_all_indicators(AAPL)\n",
    "\n",
    "# Drop rows with NaN values introduced by shifting and indicator calculations\n",
    "aapl_with_indicators.dropna(inplace=True)\n",
    "# Temporarily shorten the data for faster testing\n",
    "aapl_with_indicators = aapl_with_indicators.loc['2023-01-01':'2025-01-01'].copy()\n",
    "\n",
    "print(f\"AAPL data with indicators (first 5 rows after dropping NaNs):\\n{aapl_with_indicators.head()}\\n\")\n",
    "print(f\"Columns available for features: {aapl_with_indicators.columns.tolist()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e1c3e3-a9c7-4b68-b7c1-0c5a2c20689b",
   "metadata": {},
   "source": [
    "## 4. Model Building and Walk-Forward Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9b0d7a0-006f-4d9f-a8c9-04d3d2a0e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = [\n",
    "    'Previous_Close', 'Volume', 'Open', 'High', 'Low',\n",
    "    'SMA_50', 'SMA_200', 'EMA_12', 'EMA_26',\n",
    "    'MACD', 'MACD_Signal', 'MACD_Hist',\n",
    "    'RSI', 'Stoch_%K', 'Stoch_%D',\n",
    "    'BB_Upper', 'BB_Lower', 'ATR'\n",
    "]\n",
    "target = 'Close'\n",
    "\n",
    "# Ensure all features exist in the DataFrame\n",
    "existing_features = [f for f in features if f in aapl_with_indicators.columns]\n",
    "if len(existing_features) != len(features):\n",
    "    print(\"Warning: Some specified features are not in the DataFrame and will be skipped.\")\n",
    "    features = existing_features\n",
    "\n",
    "# Parameters for walk-forward validation\n",
    "train_window_size = 60 # Approximately 3 months of trading days\n",
    "test_window_size = 20  # Predict for the next 20 trading days (approx 1 month)\n",
    "\n",
    "rf_predictions = []\n",
    "baseline_predictions = []\n",
    "actual_prices = []\n",
    "\n",
    "daily_rf_mae = []\n",
    "daily_baseline_mae = []\n",
    "\n",
    "# Perform walk-forward validation\n",
    "for i in range(train_window_size, len(aapl_with_indicators) - test_window_size):\n",
    "    train_data = aapl_with_indicators.iloc[i - train_window_size : i]\n",
    "    test_data = aapl_with_indicators.iloc[i : i + test_window_size]\n",
    "\n",
    "    # Check if train_data has enough samples for fitting\n",
    "    if len(train_data) < train_window_size:\n",
    "        continue\n",
    "\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data[target]\n",
    "\n",
    "    # Random Forest Model\n",
    "    rf_model = RandomForestRegressor(n_estimators=20, random_state=42, n_jobs=-1) # n_jobs=-1 to use all cores\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    for j in range(len(test_data)):\n",
    "        current_test_features = test_data[features].iloc[[j]] # Need to pass as DataFrame\n",
    "        current_actual = test_data[target].iloc[j]\n",
    "        current_previous_close = test_data['Previous_Close'].iloc[j]\n",
    "\n",
    "        # Get prediction from RF model\n",
    "        rf_pred = rf_model.predict(current_test_features)[0]\n",
    "\n",
    "        # Get prediction from baseline model (previous day's close)\n",
    "        baseline_pred = current_previous_close\n",
    "\n",
    "        rf_predictions.append(rf_pred)\n",
    "        baseline_predictions.append(baseline_pred)\n",
    "        actual_prices.append(current_actual)\n",
    "\n",
    "        daily_rf_mae.append(mean_absolute_error([current_actual], [rf_pred]))\n",
    "        daily_baseline_mae.append(mean_absolute_error([current_actual], [baseline_pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a6d91f-0e10-4f51-b924-a7e2b85e09f5",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "g1a2d91f-0e10-4f51-b924-a7e2b85e09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to Series for easier plotting and analysis\n",
    "rf_preds_series = pd.Series(rf_predictions, index=aapl_with_indicators.index[train_window_size : len(aapl_with_indicators) - test_window_size + len(rf_predictions) - 1])\n",
    "baseline_preds_series = pd.Series(baseline_predictions, index=aapl_with_indicators.index[train_window_size : len(aapl_with_indicators) - test_window_size + len(baseline_predictions) - 1])\n",
    "actual_prices_series = pd.Series(actual_prices, index=aapl_with_indicators.index[train_window_size : len(aapl_with_indicators) - test_window_size + len(actual_prices) - 1])\n",
    "\n",
    "daily_rf_mae_series = pd.Series(daily_rf_mae, index=actual_prices_series.index)\n",
    "daily_baseline_mae_series = pd.Series(daily_baseline_mae, index=actual_prices_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "h2b3e0e0-f3b1-4f10-9b34-d0e1c3e3a9c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Calculate overall MAE and MSE\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m overall_rf_mae = \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactual_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf_predictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m overall_rf_mse = mean_squared_error(actual_prices, rf_predictions)\n\u001b[32m      5\u001b[39m overall_baseline_mae = mean_absolute_error(actual_prices, baseline_predictions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\Documents\\GISMA\\Data Mining\\Stock-Predictions\\data_mining_env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\Documents\\GISMA\\Data Mining\\Stock-Predictions\\data_mining_env\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:284\u001b[39m, in \u001b[36mmean_absolute_error\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[32m    229\u001b[39m \n\u001b[32m    230\u001b[39m \u001b[33;03mThe mean absolute error is a non-negative floating point value, where best value\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m \u001b[33;03m0.85...\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m xp, _ = get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[32m    283\u001b[39m _, y_true, y_pred, sample_weight, multioutput = (\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m )\n\u001b[32m    289\u001b[39m output_errors = _average(\n\u001b[32m    290\u001b[39m     xp.abs(y_pred - y_true), weights=sample_weight, axis=\u001b[32m0\u001b[39m, xp=xp\n\u001b[32m    291\u001b[39m )\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\Documents\\GISMA\\Data Mining\\Stock-Predictions\\data_mining_env\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:209\u001b[39m, in \u001b[36m_check_reg_targets_with_floating_dtype\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Ensures y_true, y_pred, and sample_weight correspond to same regression task.\u001b[39;00m\n\u001b[32m    161\u001b[39m \n\u001b[32m    162\u001b[39m \u001b[33;03mExtends `_check_reg_targets` by automatically selecting a suitable floating-point\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    205\u001b[39m \u001b[33;03m    correct keyword.\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    207\u001b[39m dtype_name = _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp=xp)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m y_type, y_true, y_pred, sample_weight, multioutput = \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y_type, y_true, y_pred, sample_weight, multioutput\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\Documents\\GISMA\\Data Mining\\Stock-Predictions\\data_mining_env\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:115\u001b[39m, in \u001b[36m_check_reg_targets\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, dtype, xp)\u001b[39m\n\u001b[32m    112\u001b[39m xp, _ = get_namespace(y_true, y_pred, multioutput, xp=xp)\n\u001b[32m    114\u001b[39m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m y_true = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m y_pred = check_array(y_pred, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\Documents\\GISMA\\Data Mining\\Stock-Predictions\\data_mining_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1128\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1126\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1129\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1130\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1131\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1132\u001b[39m         )\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1135\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# Calculate overall MAE and MSE\n",
    "overall_rf_mae = mean_absolute_error(actual_prices, rf_predictions)\n",
    "overall_rf_mse = mean_squared_error(actual_prices, rf_predictions)\n",
    "\n",
    "overall_baseline_mae = mean_absolute_error(actual_prices, baseline_predictions)\n",
    "overall_baseline_mse = mean_squared_error(actual_prices, baseline_predictions)\n",
    "\n",
    "print(f\"Overall Random Forest MAE: {overall_rf_mae:.3f}\")\n",
    "print(f\"Overall Random Forest MSE: {overall_rf_mse:.3f}\")\n",
    "print(f\"Overall Baseline (Previous Close) MAE: {overall_baseline_mae:.3f}\")\n",
    "print(f\"Overall Baseline (Previous Close) MSE: {overall_baseline_mse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i3c4f1f1-0e10-4f51-b924-a7e2b85e09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting predictions vs actuals\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.style.use('dark_background')\n",
    "plt.plot(actual_prices_series.index, actual_prices_series, label='Actual Close Price', color='white', linewidth=2)\n",
    "plt.plot(rf_preds_series.index, rf_preds_series, label='Random Forest Prediction', color='cyan', linestyle='--')\n",
    "plt.plot(baseline_preds_series.index, baseline_preds_series, label='Baseline Prediction (Previous Close)', color='yellow', linestyle=':')\n",
    "plt.title('AAPL Stock Price Prediction: Random Forest vs Baseline')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j4d5g2g2-f3b1-4f10-9b34-d0e1c3e3a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Daily MAE for comparison\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.style.use('dark_background')\n",
    "plt.plot(daily_rf_mae_series.index, daily_rf_mae_series, label='Random Forest Daily MAE', color='cyan')\n",
    "plt.plot(daily_baseline_mae_series.index, daily_baseline_mae_series, label='Baseline Daily MAE', color='yellow', linestyle='--')\n",
    "plt.title('Daily Mean Absolute Error: Random Forest vs Baseline (AAPL)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a3b91d-0e10-4f51-b924-a7e2b85e09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Feature Importance from Random Forest\n",
    "if 'rf_model' in locals():\n",
    "    importances = rf_model.feature_importances_\n",
    "    feature_names = features # Use the list of features directly\n",
    "    \n",
    "    # Check if lengths match before zipping\n",
    "    if len(importances) == len(feature_names):\n",
    "        feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "        feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.style.use('dark_background')\n",
    "        plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.title('Random Forest Feature Importance')\n",
    "        plt.gca().invert_yaxis() # Invert y-axis to have the most important feature at the top\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Error: Mismatch between feature_importances_ and feature names length.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
